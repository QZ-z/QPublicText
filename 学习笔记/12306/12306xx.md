语雀密码，stko

# 数据库相关

## 用户管理

会员相关核心数据库表如下：

- `t_user `会员数据表：存储会员账号、密码、证件号、邮箱、手机号等信息
- `t_user_mail `会员邮箱数据表：存储会员邮箱和用户名的关系
- `t_user_phone `会员手机号数据表：存储会员手机号和用户名的关系

会员相关拓展功能表如下：

- `t_user_reuse` 用户名可复用表：存储已被注销的可用用户名
- `t_user_deletion`：用户证件号注销表：存储被注销过得证件号记录数据

![image-20240527194942294](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240527194942294.png)

- `t_passenger`：乘车人数据表，用户与用户乘车人是一对多的关系

![image-20240527195058658](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240527195058658.png)

## 列车管理

`t_train`：列车表，存储每天生成的行驶列车数据。

`t_carriage`：列车车厢表，存储每趟列车对应的车厢数据，包括车厢类型。

`t_train_station `：列车站点表，存储列车行驶站点顺序表。

`t_train_station_relation`：列车站点关联表，存储列车行驶站点关联关系表。

`t_train_station_price`：列车站点价格表，存储列车站点关联关系不同座位价格表。

![image-20240527195353250](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240527195353250.png)

## 订单管理

`t_order`：订单主表，用户购买的单次车票，就对应一个订单。但是有可能一个订单中会有多个乘车人，所以还会有订单明细表。

`t_order_item`：订单明细表，一个订单可能有多个乘车人，多个乘车人就对应多个订单明细。

`t_order_item_passenger`：订单明细乘车人表，因为订单表和订单明细表分库分表规则所致，乘车人无法查看本人车票订单，所以创建了这个关联表。通过【证件号】关联订单

![image-20240527195647624](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240527195647624.png)

## 支付管理

`t_pay`：订单支付表，存储用户支付车票相关数据

## JDBC 和 Proxy 优劣势

JDBC： 

- 优点：性能较高，通过 JDBC 直接向 MySQL 发起请求调用。
- 优点：使用较为简单，理论上无需修改代码，仅需使用 ShardingSphere 的配置即可。
- 缺点：需要修改项目配置以及引入 Jar 包。
- 缺点：对应用的内存有一定影响。

Proxy： 

- 优点：无需对现有项目做任何配置或代码变更，将数据库的地址改为 Proxy 的地址即可。
- 优点：Proxy 对 Java 应用内存没有任何影响。
- 优点：分片后无法知道一条数据记录到底在那张表，Proxy 是屏蔽了分片逻辑，可直接操作逻辑表。
- 缺点：JDBC 操作 MySQL 是点对点的，但是 Proxy 多了一层链路。

为什么选择 ShardingSphere？

- 拥有活跃的社区，能够提供及时的技术支持和更新；
- 代码质量极高，经过严格测试和验证，稳定可靠；
- 提供丰富的功能，满足多样化的业务需求。

## 用户表分库分表策略

根据当前用户表的数据量为 10 亿，并且每年新增 1000 万用户，预估未来系统的生命周期较长，数据量大概会达到 30 亿左右。基于这个数据量，我们预估单表的数据量在 2000 万左右，因此需要分大约 150 张表来容纳这些数据。

2000 万作为一个经验值。这个数据量既不会过小，同时又能保证增删改查等操作相对流畅

### 分片键选择

选择分库分表中的分片键（Sharding Key）是一个关键决策，它直接影响了分库分表的性能和可扩展性。以下是一些选择分片键的关键因素：

1. **访问频率**：选择分片键应考虑数据的访问频率。将经常访问的数据放在同一个分片上，可以提高查询性能和降低跨分片查询的开销。
2. **数据均匀性**：分片键应该保证数据的均匀分布在各个分片上，避免出现热点数据集中在某个分片上的情况。
3. **业务关联性**：分片键应该与业务关联紧密，这样可以避免跨分片查询和跨库事务的复杂性。
4. **数据不可变**：一旦选择了分片键，它应该是不可变的，不能随着业务的变化而频繁修改。

选`username`

### 分片配置

分 2 个库以及对应业务 16 张表

```yaml
# 数据源集合
dataSources:
  ds_0:
    dataSourceClassName: com.zaxxer.hikari.HikariDataSource
    driverClassName: com.mysql.cj.jdbc.Driver
    jdbcUrl: jdbc:mysql://127.0.0.1:3306/12306_user_0?useUnicode=true&characterEncoding=UTF-8&rewriteBatchedStatements=true&allowMultiQueries=true&serverTimezone=Asia/Shanghai
    username: root
    password: root

  ds_1:
    dataSourceClassName: com.zaxxer.hikari.HikariDataSource
    driverClassName: com.mysql.cj.jdbc.Driver
    jdbcUrl: jdbc:mysql://127.0.0.1:3306/12306_user_1?useUnicode=true&characterEncoding=UTF-8&rewriteBatchedStatements=true&allowMultiQueries=true&serverTimezone=Asia/Shanghai
    username: root
    password: root

rules:
  - !SHARDING
    tables:
      t_user:
        # 真实数据节点，比如数据库源以及数据库在数据库中真实存在的
        actualDataNodes: ds_${0..1}.t_user_${0..15}
        # 分库策略
        databaseStrategy:
          # 用于单分片键的标准分片场景
          standard:
            # 分片键
            shardingColumn: username
            # 分片算法，对应 rules[0].shardingAlgorithms
            shardingAlgorithmName: user_database_hash_mod
        # 分表策略
        tableStrategy:
          # 用于单分片键的标准分片场景
          standard:
            # 分片键
            shardingColumn: username
            # 分片算法，对应 rules[0].shardingAlgorithms
            shardingAlgorithmName: user_table_hash_mod
    # 分片算法
    shardingAlgorithms:
      # 数据库分片算法
      user_database_hash_mod:
        # 根据分片键 Hash 分片
        type: HASH_MOD
        # 分片数量
        props:
          sharding-count: 2
      # 数据表分片算法
      user_table_hash_mod:
        # 根据分片键 Hash 分片
        type: HASH_MOD
        # 分片数量
        props:
          sharding-count: 16
# 展现逻辑 SQL & 真实 SQL
props:
  sql-show: true
```

## 订单表分库分表

用户要能查到自己的订单，同时也要支持订单号精准查询

基础的解决方案：用用户id和订单id两个字段做分片键

缺点：不方便，每次都要带这两个字段

### 基因法做分片键

将用户的后六位数据冗余到订单号中，【用户ID的后六位】用作分库分表

使用用户id或者订单号的时候，都有用户id的后六位

### 订单号生成

雪花算法生成的分布式ID+用户ID的后六位

### 分库分表配置

`shardingsphere-config.yaml`

```yaml
# 数据源集合，也就是咱们刚才说的分两个库
dataSources:
  ds_0:
    dataSourceClassName: com.zaxxer.hikari.HikariDataSource
    driverClassName: com.mysql.cj.jdbc.Driver
    jdbcUrl: jdbc:mysql://127.0.0.1:3306/12306_order_0?useUnicode=true&characterEncoding=UTF-8&rewriteBatchedStatements=true&allowMultiQueries=true&serverTimezone=Asia/Shanghai
    username: root
    password: root

  ds_1:
    dataSourceClassName: com.zaxxer.hikari.HikariDataSource
    driverClassName: com.mysql.cj.jdbc.Driver
    jdbcUrl: jdbc:mysql://127.0.0.1:3306/12306_order_1?useUnicode=true&characterEncoding=UTF-8&rewriteBatchedStatements=true&allowMultiQueries=true&serverTimezone=Asia/Shanghai
    username: root
    password: root

rules:
  	# 分片规则
    - !SHARDING
    # 分片表
    tables:
      # 订单表
      t_order:
        # 真实的数据节点，也对应着在数据库中存储的真实表
        actualDataNodes: ds_${0..1}.t_order_${0..15}
        # 分库策略
        databaseStrategy:
          # 复合分库策略（多个分片键）
          complex:
            # 用户 ID 和订单号
            shardingColumns: user_id,order_sn
            # 搜索 order_database_complex_mod 下方会有分库算法
            shardingAlgorithmName: order_database_complex_mod
        # 分表策略
        tableStrategy:
          # 复合分表策略（多个分片键）
          complex:
            # 用户 ID 和订单号
            shardingColumns: user_id,order_sn
            # 搜索 order_table_complex_mod 下方会有分表算法
            shardingAlgorithmName: order_table_complex_mod
      # 订单明细表，规则同订单表
      t_order_item:
        actualDataNodes: ds_${0..1}.t_order_item_${0..15}
        databaseStrategy:
          complex:
            shardingColumns: user_id,order_sn
            shardingAlgorithmName: order_item_database_complex_mod
        tableStrategy:
          complex:
            shardingColumns: user_id,order_sn
            shardingAlgorithmName: order_item_table_complex_mod
    # 分片算法
    shardingAlgorithms:
      # 订单分库算法
      order_database_complex_mod:
        # 通过加载全限定名类实现分片算法，相当于分片逻辑都在 algorithmClassName 对应的类中
        type: CLASS_BASED
        props:
          algorithmClassName: org.opengoofy.index12306.biz.orderservice.dao.algorithm.OrderCommonDataBaseComplexAlgorithm
          # 分库数量
          sharding-count: 2
          # 复合（多分片键）分库策略
          strategy: complex
      # 订单分表算法
      order_table_complex_mod:
        # 通过加载全限定名类实现分片算法，相当于分片逻辑都在 algorithmClassName 对应的类中
        type: CLASS_BASED
        props:
          algorithmClassName: org.opengoofy.index12306.biz.orderservice.dao.algorithm.OrderCommonTableComplexAlgorithm
          # 分表数量
          sharding-count: 16
          # 复合（多分片键）分表策略
          strategy: complex
      order_item_database_complex_mod:
        type: CLASS_BASED
        props:
          algorithmClassName: org.opengoofy.index12306.biz.orderservice.dao.algorithm.OrderCommonDataBaseComplexAlgorithm
          sharding-count: 2
          strategy: complex
      order_item_table_complex_mod:
        type: CLASS_BASED
        props:
          algorithmClassName: org.opengoofy.index12306.biz.orderservice.dao.algorithm.OrderCommonTableComplexAlgorithm
          sharding-count: 16
          strategy: complex
props:
  sql-show: true
```

### 自己扩展的分片逻辑

就是配置中的`org.opengoofy.index12306.biz.orderservice.dao.algorithm.OrderCommonTableComplexAlgorithm`

逻辑：

- 有无用户ID
  - 有，用用户ID后六位找表，并返回
  - 无，用订单号后六位找表，并返回

## 证件号绑定订单号路由表分库分表

订单明细乘车人表 `t_order_item_passenger`，也就是咱们证件号和订单号关联的这张表，数据量是等同于订单明细表 `t_order_item`，所以分库分表的数量直接同订单明细表即可

问题：订单明细表通过用户ID后六位查询到 ，但是该路由表需要按照证件号查询

解决：按照证件号进行 HASH_MOD 方式分库分表即可

# 用户注册模块

## 缓存穿透问题

### 布隆过滤器

![image-20240523235526302](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240523235526302.png)

用多个hash函数计算，将对应的位置置为1

不支持删除：删除当前位置可能会影响其他数据的判断

可能会产生误判，上图再加一个z，如果z经过hash算出来是0、1、4，那么会判断z存在

- 有限二进制位，元素多的时候，误判概率增加
- 如果认为有，可能会误判；如果认为没有，则不会误判

### 布隆+set

![image-20240523235903413](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240523235903413.png)

解决方案：加一个set结构，将注销的`username`放入，然后按着表中流程判断

- 判断存在的话，看看`set`里有没有，有的话说明注销了已经，可以使用
- `set`没有，说明不能使用

> 实际上依然没解决哈希碰撞带来的假阳问题，只是解决了，删除的用户名可以继续使用的问题
>
> 这样牺牲了一些用户名，这些用户名天然不可用

缺点：

- 两次查询，速度慢
- 存储要求大了

解决方案：

- 为防止有人疯狂申请注销加`set`，一个身份证只能注销5次
- 分片来防止`set`过大

实现部分

![image-20240527194327854](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240527194327854.png)

:question:一开始的删除用户可复用数据是什么意思：解决布隆过滤器不能删除的问题，数据库也存了一份在`t_user_reuse`表中

### 布隆过滤器大小设置

根据业务场景，选择适合的碰撞率来设计大小，碰撞率有计算公式`位数 = -(元素数量 * ln(期望误报率)) / (ln(2)^2)`，10亿需要内存大概是3.6GB

容量不够：设置定时任务，如果达到初始容量的一定比率，通过后台任务重建布隆过滤器

## 用户注册接口

![image-20240524001459564](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240524001459564.png)

### 责任链设计模式

两种责任链：

- 请求会被 所有的处理器都处理一遍，不存在中途终止的情况，这里参照 MyBatis 拦截器理解，**重点在对请求过程中的数据或者行为进行改变**
- 二则是处理器链执行请求中，某一处理器执行时，如果不符合自制定规则的话，停止流程，并且剩下未执行处理器就不会被执行，大家参照 SpringMvc 拦截器理解。

优点：

- 把总的逻辑拆分，提高代码复用，简化开发
- 添加新的规则不需要改动原有代码，设计新的方法加入责任链即可

缺点：如果处理链过长或者处理时间过长，可能会对系统性能产生一定的影响

### 责任链抽象使用

实现多级接口，方便维护一类的`ChainHandler`，即类别通过上层接口获得

```java
public interface AbstractChainHandler<T> extends Ordered {
    
    /**
     * 执行责任链逻辑
     *
     * @param requestParam 责任链执行入参
     */
    void handler(T requestParam);
    
    /**
     * @return 责任链组件标识
     */
    String mark();
}

// 订单创建责任链过滤器
public interface OrderCreateChainFilter<T extends OrderCreateCommand> extends AbstractChainHandler<OrderCreateCommand> {
    
    @Override
    default String mark() {
        return OrderChainMarkEnum.ORDER_CREATE_FILTER.name();
    }
}

// 订单创建参数必填检验
@Component
public final class OrderCreateParamNotNullChainHandler implements OrderCreateChainFilter<OrderCreateCommand> {
    
    @Override
    public void handler(OrderCreateCommand requestParam) {
    	// 逻辑执行
    }
    
    @Override
    public int getOrder() {
        return 0;
    }
}
```

### 责任链注册

 `CommandLineRunner` 接口在 SpringBoot 启动完成后，执行钩子函数将所有实现责任链抽象接口的实现类进行注册到责任链上下文中

```java
public final class AbstractChainContext<T> implements CommandLineRunner {
    
    private final Map<String, List<AbstractChainHandler>> abstractChainHandlerContainer = Maps.newHashMap();
    
    /**
     * 责任链组件执行
     *
     * @param requestParam 请求参数
     */
    public void handler(String mark, T requestParam) {
        abstractChainHandlerContainer.get(mark).stream()
                .sorted(Comparator.comparing(Ordered::getOrder)).forEach(each -> each.handler(requestParam));
    }
    
    @Override
    public void run(String... args) throws Exception {
        // 获取 Spring IOC 容器中所有 AbstractChainHandler 接口实现
        Map<String, AbstractChainHandler> chainFilterMap = ApplicationContextHolder.getBeansOfType(AbstractChainHandler.class);
        chainFilterMap.forEach((beanName, bean) -> {
            List<AbstractChainHandler> abstractChainHandlers = abstractChainHandlerContainer.get(bean.mark());
            if (abstractChainHandlers == null) {
                abstractChainHandlers = new ArrayList();
            }
            abstractChainHandlers.add(bean);
            // 根据 mark 标识将责任链模式分类，放入责任链容器上下文中
            abstractChainHandlerContainer.put(bean.mark(), abstractChainHandlers);
        });
    }
}
```

### 责任链使用

```java
@RequiredArgsConstructor
public class OrderServiceImpl implements OrderService {

    private final AbstractChainContext<OrderCreateCommand> abstractChainContext;
  
    public String createOrder(OrderCreateCommand requestParam) {
        // 责任链模式: 执行订单创建参数验证
        abstractChainContext.handler(OrderChainMarkEnum.ORDER_CREATE_FILTER.name(), requestParam);
    }
}
```

## 路由表设计

采用用户名分表，但是可以使用用户名、邮箱或手机号中的任意一个搭配密码进行登录

防止因为不带用户名造成的读扩散，设计两张路由表：

- 用户手机号表，采用手机号分片
- 用户邮箱表，采用邮箱进行分片

使用手机号查询的时候，先根据手机号拿到用户名，再查用户表

缺点：

- 引入额外查询，性能低
- 维护成本会随着数据量的增加和业务的发展增加

## 用户敏感信息展示脱敏

在 SpringMVC 返回数据时，将默认的 Jackson 序列化器进行指定，替换为包装后的序列化器，方便做脱敏展示

通过执行自定义的序列化器，前端调用 HTTP 请求获取数据时，SpringMVC 通过 Jackson 进行序列化数据时，操作证件号码和手机号两个字段就会采用自定义的序列化器，完成敏感信息脱敏功能

存在问题：后端服务中调用乘车人信息接口，会返回脱敏的信息

解决：拆分一个新的实体，后端用这个，相应的字段不加自定义的序列化器

#  [列车数据检索](https://www.yuque.com/magestack/12306/tygc8hs113al2c2z)

## 验证数据是否正确

责任链模式，主要包含：

1. 检查相关数据是否为空或空的字符串，这个是最先被执行的
2. 检查数据是否正确
   1. 日期出发不能小于当前
   2. 出发和目的是否存在
   3. .......

![image-20240529103343379](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240529103343379.png)

:question:这个地方为什么要再查询一次。

:warning:之后代码不使用图片，使用代码块格式

## 加载城市数据

完成功能：搜索北京南到杭州东，会列出北京到杭州的所有列车

实现：通过站点关联到城市，通过城市查询列车，redis与mysql都用

## 查询列车站点信息

```java
TrainDO trainDO = distributedCache.safeGet(
                        TRAIN_INFO + each.getTrainId(),
                        TrainDO.class,
                        () -> trainMapper.selectById(each.getTrainId()),
                        ADVANCE_TICKET_DAY,
                        TimeUnit.DAYS);
```

:question:`distributedCache`是怎么实现的

使用Redis而不是ES的原因，允许的搜索信息是一个三元组`出发城市，到达城市，出发日`，由这个三元组确定的列车信息不会有特别多，redis中采用如下结构解决

![image-20240529110031811](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240529110031811.png)



# 购票流程

## v1分布式锁



## v2令牌桶限流+分布式锁

## 座位分配

一次购买多个座位，尽量挨着

优先等级从高到低：

- 相同车厢相邻座位
- 相同车厢不相邻座位
- 不同车厢不相邻座位

> 如果一次购票的数量超过了一排相邻的数目，需要对人员进行拆分



# 乘车人本人车票订单查看

背景：别人帮助买了车票之后，自己注册12306之后，查询本人车票可以看到本人的车票数据

解决：

证件号是必要的，所以设立路由表，表中通过证件号绑定订单号，再关联订单表和订单明细表

该表分片键：证件号

# 订单延时关闭功能技术选型

## 定时任务

通过调度平台实现定时任务的执行，具体的任务是：根据订单创建时间扫描所有到期的订单，并执行关闭订单的操作

优点：简单

缺点：

1. 延时时间不精确
2. 不适合高并发：定时任务执行频率固定，无法根据实际订单情况调整
3. 分库分表下存在问题：根据订单创建时间扫描会造成读扩散问题

## RabbitMQ

创建两个队列：订单队列和死信队列

订单队列保存需要延时关闭的订单信息，死信队列用于存储时间到达后的订单消息。

缺点：

1. 延时精度：RabbitMQ 的延时消息特性是基于消息的 TTL（Time-To-Live）来实现的，因此消息的延时时间并不是完全准确的，可能会有一定的误差。在处理订单十分钟延时关闭时，可能会有一些订单的关闭时间略晚于预期时间。
2. 高并发问题：如果系统中有大量的订单需要延时关闭，而订单关闭操作非常复杂耗时，可能会导致消息队列中的消息堆积。这样就可能导致延时关闭操作无法及时处理，影响订单的实际关闭时间。
3. 重复消息问题：由于网络原因或其他不可预知的因素，可能会导致消息重复发送到订单队列。如果没有处理好消息的幂等性，可能会导致订单重复关闭的问题，从而造成数据不一致或其他异常情况。
4. 可靠性问题：RabbitMQ 是一个消息中间件，它是一个独立的系统。如果 RabbitMQ 本身出现故障或宕机，可能会导致订单延时关闭功能失效。因此，在使用 RabbitMQ 实现延时关闭功能时，需要考虑如何保证 RabbitMQ 的高可用性和稳定性

> 延时精度和高并发属于一类问题，取决于客户端的消费能力
>
> 重复消费问题是所有消息中间件都需要解决，需要通过消息表等幂等解决方案解决
>
> 可用性是RabbitMQ自己的问题，它在可用性方面比较弱，部分场景下会存在单点故障问题



## Redis过期监听



# 核心技术文档部分

## [雪花算法](https://www.yuque.com/magestack/12306/ciigw9ctq0v90u3w)

使用场景：全局唯一ID

优点：

1. 高性能高可用：生成时不依赖于数据库，完全在内存中生成。
2. 高吞吐：每秒钟能生成数百万的自增 ID。
3. ID 自增：存入数据库中，索引效率高。

缺点：依赖系统时间的一致性，如果系统时间被回调或改变，可能会造成ID冲突或者重复

![image-20240529101526086](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240529101526086.png)

不使用：1bit，最高位是符号位，0 表示正，1 表示负，固定为 0。

时间戳：41bit，毫秒级的时间戳（41 位的长度可以使用 69 年）。

标识位：5bit 数据中心 ID，5bit 工作机器 ID，两个标识位组合起来最多可以支持部署 1024 个节点（$2^{10}$）。

序列号：12bit 递增序列号，细分毫秒内，12bit 每毫秒可产生 4096 个 ID。

> 默认64bit，long，可以进行设置，扩充支持时间，扩充支持的节点数，增加序列号提升并发能力

### 重复问题

冲突前提：

1. 集群部署，部分机器标志位一致
2. 存在并发场景
3. 同一毫秒下才可能重复

### 标识位定义

Mybatis-Plus 标识位的获取依赖 Mac 地址和进程 PID，会有小几率问题

### 重复问题解决方案

##### 预分配

上线之前统计节点数，人工申请，不支持节点动态扩容

#### 动态分配

将标识位放在Redis、Zookeeper、MySQL 等中间件，在服务启动的时候去请求标识位

> 注意是全局唯一，还是服务内唯一

一种方案：

redis中使用`Hash`结构，包含两个键值对：`dataCenterId `和 `workerId`。

![image-20240529102347955](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240529102347955.png)

> 是一个循环结构，两个都到$2^{5}$之后，会归零重新开始

#### 开源分布式ID框架

Leaf 和 Uid 都有实现雪花算法，Leaf 额外提供了号段模式生成 ID。

美团 Leaf：https://github.com/Meituan-Dianping/Leaf

百度 Uid：https://github.com/baidu/uid-generator

> 大部分情况雪花算法就够了，不建议引入开源方案增加系统复杂度

## 敏感信息加密

`application.yaml` 配置文件修改配置，将数据库驱动变更为ShardingSphere Driver。

并配置 `shardingsphere-config.yaml` 相关配置。下边删除了分库分表的相关配置，仅保留了加密相关的配置

```yaml
# 配置数据源，底层被 ShardingSphere 进行了代理
dataSources:
  ds_0:
    dataSourceClassName: com.zaxxer.hikari.HikariDataSource
    driverClassName: com.mysql.cj.jdbc.Driver
    jdbcUrl: jdbc:mysql://127.0.0.1:3306/12306_user_0?useUnicode=true&characterEncoding=UTF-8&rewriteBatchedStatements=true&allowMultiQueries=true&serverTimezone=Asia/Shanghai
    username: root
    password: root

rules:
# 数据加密存储规则
  - !ENCRYPT
    # 需要加密的表集合
    tables:
      # 用户表
      t_user:
        # 用户表中哪些字段需要进行加密
        columns:
          # 身份证字段，逻辑字段，不一定是在数据库中真实存在
          id_card:
            # 身份证字段存储的密文字段，这个是数据库中真实存在的字段
            cipherColumn: id_card
            # 身份证字段加密算法
            encryptorName: common_encryptor
          phone:
            cipherColumn: phone
            encryptorName: common_encryptor
          mail:
            cipherColumn: mail
            encryptorName: common_encryptor
          address:
            cipherColumn: address
            encryptorName: common_encryptor
        # 是否按照密文字段查询
        queryWithCipherColumn: true
    # 加密算法
    encryptors:
      # 自定义加密算法名称
      common_encryptor:
        # 加密算法类型
        type: AES
        props:
          # AES 加密密钥
          aes-key-value: d6oadClrrb9A3GWo
props:
  sql-show: true
```

![image-20240611143011122](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240611143011122.png)

Apache ShardingSphere 会将用户请求的明文进行加密后存储到底层数据库；并在用户查询时，将密文从数据库中取出进行解密后返回给终端用户。 通过屏蔽对数据的加密处理，使用户无需感知解析 SQL、数据加密、数据解密的处理过程，就像在使用普通数据一样使用加密数据
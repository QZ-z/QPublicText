语雀密码，stko

# 数据库相关

## 用户管理

会员相关核心数据库表如下：

- `t_user `会员数据表：存储会员账号、密码、证件号、邮箱、手机号等信息
- `t_user_mail `会员邮箱数据表：存储会员邮箱和用户名的关系
- `t_user_phone `会员手机号数据表：存储会员手机号和用户名的关系

会员相关拓展功能表如下：

- `t_user_reuse` 用户名可复用表：存储已被注销的可用用户名
- `t_user_deletion`：用户证件号注销表：存储被注销过得证件号记录数据

![image-20240527194942294](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240527194942294.png)

- `t_passenger`：乘车人数据表，用户与用户乘车人是一对多的关系

![image-20240527195058658](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240527195058658.png)

## 列车管理

`t_train`：列车表，存储每天生成的行驶列车数据。

`t_carriage`：列车车厢表，存储每趟列车对应的车厢数据，包括车厢类型。

`t_train_station `：列车站点表，存储列车行驶站点顺序表。

`t_train_station_relation`：列车站点关联表，存储列车行驶站点关联关系表。

`t_train_station_price`：列车站点价格表，存储列车站点关联关系不同座位价格表。

![image-20240527195353250](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240527195353250.png)

## 订单管理

`t_order`：订单主表，用户购买的单次车票，就对应一个订单。但是有可能一个订单中会有多个乘车人，所以还会有订单明细表。

`t_order_item`：订单明细表，一个订单可能有多个乘车人，多个乘车人就对应多个订单明细。

`t_order_item_passenger`：订单明细乘车人表，因为订单表和订单明细表分库分表规则所致，乘车人无法查看本人车票订单，所以创建了这个关联表。通过【证件号】关联订单

![image-20240527195647624](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240527195647624.png)

## 支付管理

`t_pay`：订单支付表，存储用户支付车票相关数据

## JDBC 和 Proxy 优劣势

JDBC： 

- 优点：性能较高，通过 JDBC 直接向 MySQL 发起请求调用。
- 优点：使用较为简单，理论上无需修改代码，仅需使用 ShardingSphere 的配置即可。
- 缺点：需要修改项目配置以及引入 Jar 包。
- 缺点：对应用的内存有一定影响。

Proxy： 

- 优点：无需对现有项目做任何配置或代码变更，将数据库的地址改为 Proxy 的地址即可。
- 优点：Proxy 对 Java 应用内存没有任何影响。
- 优点：分片后无法知道一条数据记录到底在那张表，Proxy 是屏蔽了分片逻辑，可直接操作逻辑表。
- 缺点：JDBC 操作 MySQL 是点对点的，但是 Proxy 多了一层链路。

为什么选择 ShardingSphere？

- 拥有活跃的社区，能够提供及时的技术支持和更新；
- 代码质量极高，经过严格测试和验证，稳定可靠；
- 提供丰富的功能，满足多样化的业务需求。

## 用户表分库分表策略

根据当前用户表的数据量为 10 亿，并且每年新增 1000 万用户，预估未来系统的生命周期较长，数据量大概会达到 30 亿左右。基于这个数据量，我们预估单表的数据量在 2000 万左右，因此需要分大约 150 张表来容纳这些数据。

2000 万作为一个经验值。这个数据量既不会过小，同时又能保证增删改查等操作相对流畅

### 分片键选择

选择分库分表中的分片键（Sharding Key）是一个关键决策，它直接影响了分库分表的性能和可扩展性。以下是一些选择分片键的关键因素：

1. **访问频率**：选择分片键应考虑数据的访问频率。将经常访问的数据放在同一个分片上，可以提高查询性能和降低跨分片查询的开销。
2. **数据均匀性**：分片键应该保证数据的均匀分布在各个分片上，避免出现热点数据集中在某个分片上的情况。
3. **业务关联性**：分片键应该与业务关联紧密，这样可以避免跨分片查询和跨库事务的复杂性。
4. **数据不可变**：一旦选择了分片键，它应该是不可变的，不能随着业务的变化而频繁修改。

选`username`

### 分片配置

分 2 个库以及对应业务 16 张表

```yaml
# 数据源集合
dataSources:
  ds_0:
    dataSourceClassName: com.zaxxer.hikari.HikariDataSource
    driverClassName: com.mysql.cj.jdbc.Driver
    jdbcUrl: jdbc:mysql://127.0.0.1:3306/12306_user_0?useUnicode=true&characterEncoding=UTF-8&rewriteBatchedStatements=true&allowMultiQueries=true&serverTimezone=Asia/Shanghai
    username: root
    password: root

  ds_1:
    dataSourceClassName: com.zaxxer.hikari.HikariDataSource
    driverClassName: com.mysql.cj.jdbc.Driver
    jdbcUrl: jdbc:mysql://127.0.0.1:3306/12306_user_1?useUnicode=true&characterEncoding=UTF-8&rewriteBatchedStatements=true&allowMultiQueries=true&serverTimezone=Asia/Shanghai
    username: root
    password: root

rules:
  - !SHARDING
    tables:
      t_user:
        # 真实数据节点，比如数据库源以及数据库在数据库中真实存在的
        actualDataNodes: ds_${0..1}.t_user_${0..15}
        # 分库策略
        databaseStrategy:
          # 用于单分片键的标准分片场景
          standard:
            # 分片键
            shardingColumn: username
            # 分片算法，对应 rules[0].shardingAlgorithms
            shardingAlgorithmName: user_database_hash_mod
        # 分表策略
        tableStrategy:
          # 用于单分片键的标准分片场景
          standard:
            # 分片键
            shardingColumn: username
            # 分片算法，对应 rules[0].shardingAlgorithms
            shardingAlgorithmName: user_table_hash_mod
    # 分片算法
    shardingAlgorithms:
      # 数据库分片算法
      user_database_hash_mod:
        # 根据分片键 Hash 分片
        type: HASH_MOD
        # 分片数量
        props:
          sharding-count: 2
      # 数据表分片算法
      user_table_hash_mod:
        # 根据分片键 Hash 分片
        type: HASH_MOD
        # 分片数量
        props:
          sharding-count: 16
# 展现逻辑 SQL & 真实 SQL
props:
  sql-show: true
```

## 订单表分库分表

用户要能查到自己的订单，同时也要支持订单号精准查询

基础的解决方案：用用户id和订单id两个字段做分片键

缺点：不方便，每次都要带这两个字段

### 基因法做分片键

将用户的后六位数据冗余到订单号中，【用户ID的后六位】用作分库分表

使用用户id或者订单号的时候，都有用户id的后六位

### 订单号生成

雪花算法生成的分布式ID+用户ID的后六位

### 分库分表配置

`shardingsphere-config.yaml`

```yaml
# 数据源集合，也就是咱们刚才说的分两个库
dataSources:
  ds_0:
    dataSourceClassName: com.zaxxer.hikari.HikariDataSource
    driverClassName: com.mysql.cj.jdbc.Driver
    jdbcUrl: jdbc:mysql://127.0.0.1:3306/12306_order_0?useUnicode=true&characterEncoding=UTF-8&rewriteBatchedStatements=true&allowMultiQueries=true&serverTimezone=Asia/Shanghai
    username: root
    password: root

  ds_1:
    dataSourceClassName: com.zaxxer.hikari.HikariDataSource
    driverClassName: com.mysql.cj.jdbc.Driver
    jdbcUrl: jdbc:mysql://127.0.0.1:3306/12306_order_1?useUnicode=true&characterEncoding=UTF-8&rewriteBatchedStatements=true&allowMultiQueries=true&serverTimezone=Asia/Shanghai
    username: root
    password: root

rules:
  	# 分片规则
    - !SHARDING
    # 分片表
    tables:
      # 订单表
      t_order:
        # 真实的数据节点，也对应着在数据库中存储的真实表
        actualDataNodes: ds_${0..1}.t_order_${0..15}
        # 分库策略
        databaseStrategy:
          # 复合分库策略（多个分片键）
          complex:
            # 用户 ID 和订单号
            shardingColumns: user_id,order_sn
            # 搜索 order_database_complex_mod 下方会有分库算法
            shardingAlgorithmName: order_database_complex_mod
        # 分表策略
        tableStrategy:
          # 复合分表策略（多个分片键）
          complex:
            # 用户 ID 和订单号
            shardingColumns: user_id,order_sn
            # 搜索 order_table_complex_mod 下方会有分表算法
            shardingAlgorithmName: order_table_complex_mod
      # 订单明细表，规则同订单表
      t_order_item:
        actualDataNodes: ds_${0..1}.t_order_item_${0..15}
        databaseStrategy:
          complex:
            shardingColumns: user_id,order_sn
            shardingAlgorithmName: order_item_database_complex_mod
        tableStrategy:
          complex:
            shardingColumns: user_id,order_sn
            shardingAlgorithmName: order_item_table_complex_mod
    # 分片算法
    shardingAlgorithms:
      # 订单分库算法
      order_database_complex_mod:
        # 通过加载全限定名类实现分片算法，相当于分片逻辑都在 algorithmClassName 对应的类中
        type: CLASS_BASED
        props:
          algorithmClassName: org.opengoofy.index12306.biz.orderservice.dao.algorithm.OrderCommonDataBaseComplexAlgorithm
          # 分库数量
          sharding-count: 2
          # 复合（多分片键）分库策略
          strategy: complex
      # 订单分表算法
      order_table_complex_mod:
        # 通过加载全限定名类实现分片算法，相当于分片逻辑都在 algorithmClassName 对应的类中
        type: CLASS_BASED
        props:
          algorithmClassName: org.opengoofy.index12306.biz.orderservice.dao.algorithm.OrderCommonTableComplexAlgorithm
          # 分表数量
          sharding-count: 16
          # 复合（多分片键）分表策略
          strategy: complex
      order_item_database_complex_mod:
        type: CLASS_BASED
        props:
          algorithmClassName: org.opengoofy.index12306.biz.orderservice.dao.algorithm.OrderCommonDataBaseComplexAlgorithm
          sharding-count: 2
          strategy: complex
      order_item_table_complex_mod:
        type: CLASS_BASED
        props:
          algorithmClassName: org.opengoofy.index12306.biz.orderservice.dao.algorithm.OrderCommonTableComplexAlgorithm
          sharding-count: 16
          strategy: complex
props:
  sql-show: true
```

### 自己扩展的分片逻辑

就是配置中的`org.opengoofy.index12306.biz.orderservice.dao.algorithm.OrderCommonTableComplexAlgorithm`

逻辑：

- 有无用户ID
  - 有，用用户ID后六位找表，并返回
  - 无，用订单号后六位找表，并返回

## 证件号绑定订单号路由表分库分表

订单明细乘车人表 `t_order_item_passenger`，也就是咱们证件号和订单号关联的这张表，数据量是等同于订单明细表 `t_order_item`，所以分库分表的数量直接同订单明细表即可

问题：订单明细表通过用户ID后六位查询到 ，但是该路由表需要按照证件号查询

解决：按照证件号进行 HASH_MOD 方式分库分表即可

# 用户注册模块

## 缓存穿透问题

### 布隆过滤器

![image-20240523235526302](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240523235526302.png)

用多个hash函数计算，将对应的位置置为1

不支持删除：删除当前位置可能会影响其他数据的判断

可能会产生误判，上图再加一个z，如果z经过hash算出来是0、1、4，那么会判断z存在

- 有限二进制位，元素多的时候，误判概率增加
- 如果认为有，可能会误判；如果认为没有，则不会误判

### 布隆+set

![image-20240523235903413](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240523235903413.png)

解决方案：加一个set结构，将注销的`username`放入，然后按着表中流程判断

- 判断存在的话，看看`set`里有没有，有的话说明注销了已经，可以使用
- `set`没有，说明不能使用

> 实际上依然没解决哈希碰撞带来的假阳问题，只是解决了，删除的用户名可以继续使用的问题
>
> 这样牺牲了一些用户名，这些用户名天然不可用

缺点：

- 两次查询，速度慢
- 存储要求大了

解决方案：

- 为防止有人疯狂申请注销加`set`，一个身份证只能注销5次
- 分片来防止`set`过大

实现部分

![image-20240527194327854](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240527194327854.png)

:question:一开始的删除用户可复用数据是什么意思：解决布隆过滤器不能删除的问题，数据库也存了一份在`t_user_reuse`表中

### 布隆过滤器大小设置

根据业务场景，选择适合的碰撞率来设计大小，碰撞率有计算公式`位数 = -(元素数量 * ln(期望误报率)) / (ln(2)^2)`，10亿需要内存大概是3.6GB

容量不够：设置定时任务，如果达到初始容量的一定比率，通过后台任务重建布隆过滤器

## 用户注册接口

![image-20240524001459564](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240524001459564.png)

### 责任链设计模式

两种责任链：

- 请求会被 所有的处理器都处理一遍，不存在中途终止的情况，这里参照 MyBatis 拦截器理解，**重点在对请求过程中的数据或者行为进行改变**
- 二则是处理器链执行请求中，某一处理器执行时，如果不符合自制定规则的话，停止流程，并且剩下未执行处理器就不会被执行，大家参照 SpringMvc 拦截器理解。

优点：

- 把总的逻辑拆分，提高代码复用，简化开发
- 添加新的规则不需要改动原有代码，设计新的方法加入责任链即可

缺点：如果处理链过长或者处理时间过长，可能会对系统性能产生一定的影响

### 责任链抽象使用

实现多级接口，方便维护一类的`ChainHandler`，即类别通过上层接口获得

```java
public interface AbstractChainHandler<T> extends Ordered {
    
    /**
     * 执行责任链逻辑
     *
     * @param requestParam 责任链执行入参
     */
    void handler(T requestParam);
    
    /**
     * @return 责任链组件标识
     */
    String mark();
}

// 订单创建责任链过滤器
public interface OrderCreateChainFilter<T extends OrderCreateCommand> extends AbstractChainHandler<OrderCreateCommand> {
    
    @Override
    default String mark() {
        return OrderChainMarkEnum.ORDER_CREATE_FILTER.name();
    }
}

// 订单创建参数必填检验
@Component
public final class OrderCreateParamNotNullChainHandler implements OrderCreateChainFilter<OrderCreateCommand> {
    
    @Override
    public void handler(OrderCreateCommand requestParam) {
    	// 逻辑执行
    }
    
    @Override
    public int getOrder() {
        return 0;
    }
}
```

### 责任链注册

 `CommandLineRunner` 接口在 SpringBoot 启动完成后，执行钩子函数将所有实现责任链抽象接口的实现类进行注册到责任链上下文中

```java
public final class AbstractChainContext<T> implements CommandLineRunner {
    
    private final Map<String, List<AbstractChainHandler>> abstractChainHandlerContainer = Maps.newHashMap();
    
    /**
     * 责任链组件执行
     *
     * @param requestParam 请求参数
     */
    public void handler(String mark, T requestParam) {
        abstractChainHandlerContainer.get(mark).stream()
                .sorted(Comparator.comparing(Ordered::getOrder)).forEach(each -> each.handler(requestParam));
    }
    
    @Override
    public void run(String... args) throws Exception {
        // 获取 Spring IOC 容器中所有 AbstractChainHandler 接口实现
        Map<String, AbstractChainHandler> chainFilterMap = ApplicationContextHolder.getBeansOfType(AbstractChainHandler.class);
        chainFilterMap.forEach((beanName, bean) -> {
            List<AbstractChainHandler> abstractChainHandlers = abstractChainHandlerContainer.get(bean.mark());
            if (abstractChainHandlers == null) {
                abstractChainHandlers = new ArrayList();
            }
            abstractChainHandlers.add(bean);
            // 根据 mark 标识将责任链模式分类，放入责任链容器上下文中
            abstractChainHandlerContainer.put(bean.mark(), abstractChainHandlers);
        });
    }
}
```

### 责任链使用

```java
@RequiredArgsConstructor
public class OrderServiceImpl implements OrderService {

    private final AbstractChainContext<OrderCreateCommand> abstractChainContext;
  
    public String createOrder(OrderCreateCommand requestParam) {
        // 责任链模式: 执行订单创建参数验证
        abstractChainContext.handler(OrderChainMarkEnum.ORDER_CREATE_FILTER.name(), requestParam);
    }
}
```

## 路由表设计

采用用户名分表，但是可以使用用户名、邮箱或手机号中的任意一个搭配密码进行登录

防止因为不带用户名造成的读扩散，设计两张路由表：

- 用户手机号表，采用手机号分片
- 用户邮箱表，采用邮箱进行分片

使用手机号查询的时候，先根据手机号拿到用户名，再查用户表

缺点：

- 引入额外查询，性能低
- 维护成本会随着数据量的增加和业务的发展增加

## 用户敏感信息展示脱敏

在 SpringMVC 返回数据时，将默认的 Jackson 序列化器进行指定，替换为包装后的序列化器，方便做脱敏展示

通过执行自定义的序列化器，前端调用 HTTP 请求获取数据时，SpringMVC 通过 Jackson 进行序列化数据时，操作证件号码和手机号两个字段就会采用自定义的序列化器，完成敏感信息脱敏功能

存在问题：后端服务中调用乘车人信息接口，会返回脱敏的信息

解决：拆分一个新的实体，后端用这个，相应的字段不加自定义的序列化器

#  [列车数据检索](https://www.yuque.com/magestack/12306/tygc8hs113al2c2z)

## 验证数据是否正确

责任链模式，主要包含：

1. 检查相关数据是否为空或空的字符串，这个是最先被执行的
2. 检查数据是否正确
   1. 日期出发不能小于当前
   2. 出发和目的是否存在
   3. .......

![image-20240529103343379](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240529103343379.png)

:question:这个地方为什么要再查询一次。

:warning:之后代码不使用图片，使用代码块格式

## 加载城市数据

完成功能：搜索北京南到杭州东，会列出北京到杭州的所有列车

实现：通过站点关联到城市，通过城市查询列车，在缓存中使用Hash结构，保存列车站点与城市之间的对应关系，之后在缓存中根据`出发城市，到达城市，出发日`的三元组进行查询

redis与mysql都用

## 查询列车站点信息

```java
TrainDO trainDO = distributedCache.safeGet(
                        TRAIN_INFO + each.getTrainId(),
                        TrainDO.class,
                        () -> trainMapper.selectById(each.getTrainId()),
                        ADVANCE_TICKET_DAY,
                        TimeUnit.DAYS);
```

:question:`distributedCache`是怎么实现的

使用Redis而不是ES的原因，允许的搜索信息是一个三元组`出发城市，到达城市，出发日`，由这个三元组确定的列车信息不会有特别多，redis中采用如下结构解决

![image-20240529110031811](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240529110031811.png)

之后的大部分条件由前端进行筛选

> 列车详细信息中是没有列车余票数据的，因为这个数据是实时变更的，存入这里无法更新

## 查询列车余票信息

注意，之前的信息没有列车余票信息，余票信息单独存储

# 购票流程

![image-20240619004247943](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240619004247943.png)

## v1分布式锁

### 防重复提交

解决方案：加锁

![image-20240619004721159](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240619004721159.png)

具体实现：对HTTP的防重复提交和消息队列的幂等封装为组件库

用到的技术：SpEL（Spring Expression Language）是 Spring 框架提供的一种表达式语言，用于在运行时评估表达式，【能够在Spring应用程序中动态求值和访问对象的属性、方法调用、运算符操作等】

### 验证提交参数

责任链

### 避免分配相同座位

采用分布式锁完成，同一列车在同一时间仅有单个用户可以进行座位的分配和订单的创建

文档讲解与黑马点评中类似，不再记录

### 座位分配

一次购买多个座位，尽量挨着

优先等级从高到低：

- 相同车厢相邻座位
- 相同车厢不相邻座位
- 不同车厢不相邻座位

> 如果一次购票的数量超过了一排相邻的数目，需要对人员进行拆分

### 订单创建流程

![image-20240619005256936](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240619005256936.png)

#### [订单号生成之订单库分库分表](##订单表分库分表)

见跳转

#### 创建订单记录

- 主订单
- 订单明细
- 订单乘车人明细表：通过身份证id关联订单明细表

#### 延迟关闭订单

[订单延时关闭功能技术选型](#订单延时关闭功能技术选型)

问题：为什么要在购票服务中做订阅订单延时关闭？

避免循环依赖。

列车购票从购票服务发起，通过购票服务

- 分配座位
- 锁定座位
- 创建订单

购票服务调用了订单服务，延迟关闭订单中，涉及订单状态的变更和列车座位的变成，需要调用购票服务，构成循环依赖



## v2令牌桶限流+分布式锁

#### v1存在的问题

v1中为保障列车座位超卖以及一个座位不分配给多名用户，采用分布式锁保障数据的安全和一致性

##### 1. 瞬间高并发压垮系统

热门假期TPS高

> TPS和QPS的区别：
>
> - TPS（Transactions Per Second）是一个衡量系统性能的指标，用于表示系统在单位时间内能够处理的【事务数量】
> - QPS（Queries Per Second）是一个衡量系统负载或性能的指标，用于表示系统在单位时间内处理的【查询请求数量】
> - QPS只考虑查询，不考虑每个查询的复杂性、资源消耗和响应速度

一个 SpringBoot 应用的同一时间在运行的请求是有限的，因为 SpringBoot 处理请求底层也是个线程池在做

存在问题：大量请求会因为分布式锁的申请而发生阻塞，导致请求无法快速处理。这会导致后续请求长时间被阻塞，使系统陷入假死状态。无论请求的数量有多大，系统都无法返回响应。此外，随着请求的积累，还存在内存溢出的风险。更糟糕的是，如果 SpringBoot Tomcat 的线程池被分布式锁占用，查询请求也将无法得到响应。

##### 2. 先买票不一定有票

默认 Redisson 的获取锁是非公平锁，带来性能上优势的同时也带来了一些问题：

- 饥饿问题
- 公平性问题

解决方法：采用公平锁

##### 3. 分布式锁压力

eg. 一趟列车十几万人去抢票，最后只有几千能买到，只有这几千人请求分布式锁的行为是有意义的，其他人都是无效行为

优化思路：不让所有抢购列车的用户去申请分布式锁，只让少量用户获取

:question:这样不会产生相应的问题么

##### 4. 用户购票响应慢

v1中分布式锁，锁定整个列车（列车的唯一键列车ID）

优化思路：让不同种类座位的锁不冲突

引发问题：用户购买两种票，涉及锁重合互斥问题

### 限流解决

[限流方法参考](##令牌限流)

解决思路：令牌桶，但不会以恒定速率生成令牌，将所有没有出售的座位当作令牌放到容器中

![image-20240619110600317](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240619110600317.png)

加入这步之后，经过token过滤，只有拿到令牌的可以获取分布式锁

限流代码流程：

1. 从令牌容器中获取令牌的方法：
   1. 如果令牌容器在缓存中失效需要重新读取并放入缓存；
   2. 准备执行 Lua 脚本的数据；
   3. 最终的执行 Lua 脚本获取令牌。

==实现细则==

:one:

为了避免 Redis 极端场景下的数据被删除或者失效等问题，我们这里考虑到这种情况所以先通过判断令牌容器是否存在，存在则继续，不存在则进行加载。

令牌构成，令牌是Hash结构

令牌限流容器 Redis Key：`mading:index12306-ticket-service:ticket_availability_token_bucket:1`

- mading：项目中全局前缀标识 Key 标识。
- index12306-ticket-service:ticket_availability_token_bucket：令牌限流容器的 Key 标识。
- 1：列车 ID 信息。

Hash中元素，key标识出发、终点和座位类型，vaule标识座位余量

:two:

准备Lua脚本执行数据

最终拼接结构是Map，key是座位类型，value是该座位类型的购票人数

:three:

执行Lua脚本获取令牌

一些参数解析

- actualHashKey：存储 Redis Hash 结构的 Key 值，如上文所列 `mading:index12306-ticket-service:ticket_availability_token_bucket:1`。
- luaScriptKey：用户购买的出发站点和到达站点，比如北京南_南京南。
- seatTypeCountArray：需要扣减的座位类型以及对应数量。
- takeoutRouteDTOList：需要扣减的相关列车站点

[采用令牌限流而不是缓存限流的好处](###令牌限流的优点)

### 替换非公平锁为公平锁

公平锁特点：

- 公平性
- 可预见性

公平锁的一些缺点：

- 性能降低：公平锁需要维护一个等待队列，按照请求的顺序分配锁资源。这会增加锁的管理开销和线程调度的开销，可能导致性能下降，尤其在高并发场景下。
- 竞争增加：由于公平锁要按照请求的顺序分配锁资源，当一个线程释放锁时，需要通知等待队列中的下一个线程获取锁。这会引起更多的竞争和上下文切换，从而降低系统的吞吐量。

### 分布式锁升级

:question:分布式锁进阶，待补充

### 优化业务加锁粒度

:question:待补充

## 余票缓存与数据库一致性的保障

### 车票扣减逻辑

![image-20240620093517019](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240620093517019.png)

只要是和「济南西到杭州东」 **有交集 （或者说是有重叠）**的车站区间，余票都需要扣减

### 一致性保障方案

![image-20240620093549867](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240620093549867.png)

负责 Canal RocketMQ 消费者取名叫做 `CanalCommonSyncBinlogConsumer` 寓意着我们进行监听的所有表的数据修改 Binlog 都会通过这个消息队列进行监听

:one:需要过滤数据，只有 seat_status 字段的改变，例如由 0（可售状态）转变为 1（锁定状态），或者从 1 变为 0，才会引发余票的变化

:two:更新列车站点余票缓存逻辑

座位从0到1，生成订单减少库存

座位从1到0，订单取消或者超时关闭，增加库存

因为之前已经判断过是有变化的，所以现在只需要考虑旧数据是0还是1就行了

### 相关问题

#### 为什么订阅 Canal 的消费者不用线程池?

目前我们的方案是通过一个 RocketMQ Topic 消费 Canal 传递的 Binlog 数据变更事件。为了提高消费速度，我们可以考虑在客户端消费时增加一个线程池。此外，在消息积压情况下，我们可以利用 Hippo4 动态调整线程池大小来进步增加消费速度。

然而，需要注意的是，使用线程池消费消息会使得投递线程池的成功与消息消费成功绑定【即投递线程池之后就视为消费成功了】。如果消费过程中发生失败，我们无法再利用 RocketMQ 的消费失败重试逻辑。尽管我们可以通过其他技术方案实现重试消费逻辑，但这会增加方案的复杂性和不确定性。

相比之下，直接使用 RocketMQ 方案更加简单。因此，我们最终选择将 RocketMQ 底层线程池的线程数参数适当增大，以提高消费速度。此外，Hippo4i 可以操作RocketMQ 底层线程池，在消息积压时，通过动态调整线程池参数来解决积压问题。

#### 为什么扣减数据库需要扣减沿途车站，而缓存扣减不需要?

由于操作数据库时更改了出发站点和到达站点之间的沿途站点，导致对应的沿途车站座位数据的 Binlog 会被投递到RocketMQ 队列中。应用客户端将完全消费这些 Binlog，因此在扣减缓存时无需再对沿途站点进行扣减操作。

#### 为什么创建订单扣减库存而不是支付后扣减库存?

在我进行了真实实验后发现，在 12306 购买车票时，购买成功后几分钟乃至十几分钟内余票数量并不会减少.
在设计过程中，我主要考虑了两种库存扣减方案:下单扣减库存和支付扣减库存.

1. 下单扣减库存:
   - 操作时机:库存在下单时就进行扣减，即在用户下单时就减少库存
   - 优势:
     - 立即锁定库存:下单扣减库存可以立即锁定列车站点的库存，避免其他用户同时购买同一列车车站导致库存不足的问题
     - 简化流程:不需要等待支付完成才进行库存扣减，简化了流程
   - 劣势
   - 库存占用:下单后，如果用户不支付，库存将被长时间占用，可能导致其他用户无法购买该列车站点座位
   - 订单超时问题:如果用户下单后长时间不支付，库存将一直被占用，影响其他用户购买.
2. 支付扣减库存:
   - 操作时机:库存在支付完成时才进行扣减，即在用户支付成功后再减少库存.
   - 优势:
     - 避免库存占用:只有支付成功的订单才会减少库存，避免了长时间占用库存的问题
     - 提高订单完成率:只有支付完成的订单才会扣减库存，避免了因用户不支付而导致库存被占用的情况.
   - 劣势
     - 竞争情况: 如果多个用户同时下单购买同一商品，可能出现竞争情况，导致库存不足
     - 需要处理超时问题:需要考虑订单支付超时的情况，如果超时未支付，需要释放相应的库存

从实际场景考虑，当用户购买列车车票时，他们的目的是为了支付购买成功。如果用户已经进入支付流程，却被告知库存已售罄，这将给用户带来非常糟糕的体验为

了确保用户获得良好的用户体验，我们在设计库存扣减时选择了用户下单后立即开始扣减库存。如果用户没有完成支付或取消订单，我们会将列车站点的库存数量归还。这样做可以避免用户在进入支付流程后遇到库存不足的情况提供更好的用户购票体验。

# 乘车人本人车票订单查看

背景：别人帮助买了车票之后，自己注册12306之后，查询本人车票可以看到本人的车票数据

解决：

证件号是必要的，所以设立路由表，表中通过证件号绑定订单号，再关联订单表和订单明细表

该表分片键：证件号

# 订单延时关闭功能技术选型

## 定时任务

通过调度平台实现定时任务的执行，具体的任务是：根据订单创建时间扫描所有到期的订单，并执行关闭订单的操作

优点：简单

缺点：

1. 延时时间不精确
2. 不适合高并发：定时任务执行频率固定，无法根据实际订单情况调整
3. 分库分表下存在问题：根据订单创建时间扫描会造成读扩散问题

## RabbitMQ

创建两个队列：订单队列和死信队列

订单队列保存需要延时关闭的订单信息，死信队列用于存储时间到达后的订单消息。

缺点：

1. 延时精度：RabbitMQ 的延时消息特性是基于消息的 TTL（Time-To-Live）来实现的，因此消息的延时时间并不是完全准确的，可能会有一定的误差。在处理订单十分钟延时关闭时，可能会有一些订单的关闭时间略晚于预期时间。
2. 高并发问题：如果系统中有大量的订单需要延时关闭，而订单关闭操作非常复杂耗时，可能会导致消息队列中的消息堆积。这样就可能导致延时关闭操作无法及时处理，影响订单的实际关闭时间。
3. 重复消息问题：由于网络原因或其他不可预知的因素，可能会导致消息重复发送到订单队列。如果没有处理好消息的幂等性，可能会导致订单重复关闭的问题，从而造成数据不一致或其他异常情况。
4. 可靠性问题：RabbitMQ 是一个消息中间件，它是一个独立的系统。如果 RabbitMQ 本身出现故障或宕机，可能会导致订单延时关闭功能失效。因此，在使用 RabbitMQ 实现延时关闭功能时，需要考虑如何保证 RabbitMQ 的高可用性和稳定性

> 延时精度和高并发属于一类问题，取决于客户端的消费能力
>
> 重复消费问题是所有消息中间件都需要解决，需要通过消息表等幂等解决方案解决
>
> 可用性是RabbitMQ自己的问题，它在可用性方面比较弱，部分场景下会存在单点故障问题

## Redis过期监听

使用Redis中的过期消息监听机制

在订单创建时，将订单信息存储到 Redis，并设置过期时间为十分钟。

同时，在 Redis 中存储一个过期消息监听的键值对，键为订单号，值为待处理订单的标识。

:question:过期消息监听键值对的作用是什么？评论：记录订单信息，用作幂等处理

缺点：

1. 不够精确：Redis 的过期时间是通过定时器实现的，可能存在一定的误差，导致订单的关闭时间不是精确的十分钟。这对于某些对时间要求较高的场景可能不适用。
2. Redis 宕机：如果 Redis 宕机或重启，那些已经设置了过期时间但还未过期的订单信息将会丢失，导致这部分订单无法正确关闭。需要考虑如何处理这种异常情况。
3. 可靠性：依赖 Redis 的过期时间来实现订单关闭功能，需要确保 Redis 的高可用性和稳定性。如果 Redis 发生故障或网络问题，可能导致订单关闭功能失效。
4. 版本问题：Redis 5.0 之前是不保证延迟消息持久化的，如果客户端消费过程中宕机或者重启，这个消息不会重复投递。5.0 之后推出了 Stream 功能，有了持久化等比较完善的延迟消息功能

## Redisson

使用 `RDelayedQueue` 对象，创建订单的时候，将订单信息添加到`RDelayedQueue` 中，然后使用Redisson的监听功能监听`RDelayedQueue` ，一旦设定的时间到了，会出发监听事件，可以编写相应的处理逻辑

存在问题和Redis监听差不多，因为Redisson毕竟依赖于Redis的实现

## RocketMQ

在订单生成时，我们将订单关闭消息发送到 RocketMQ，并设置消息的延迟时间为十分钟。

RocketMQ 支持设置消息的延迟时间，可以通过设置消息的 delayLevel 来指定延迟级别，每个级别对应一种延迟时间。这样，订单关闭消息将在十分钟后自动被消费者接收到。

5.0之后支持自定义时间的延迟

对应代码部分：

```java
// 延时关闭订单消息生产者
org.opengoofy.index12306.biz.ticketservice.mq.produce.AbstractCommonSendProduceTemplate#sendMessage

// 延时关闭订单消息消费者
org.opengoofy.index12306.biz.ticketservice.mq.consumer.DelayCloseOrderConsumer#onMessage
```

优点：

- 通过重试，确保了可靠性
- 但是要防止重试造成的幂等问题

# 核心技术文档部分

## [雪花算法](https://www.yuque.com/magestack/12306/ciigw9ctq0v90u3w)

使用场景：全局唯一ID

优点：

1. 高性能高可用：生成时不依赖于数据库，完全在内存中生成。
2. 高吞吐：每秒钟能生成数百万的自增 ID。
3. ID 自增：存入数据库中，索引效率高。

缺点：依赖系统时间的一致性，如果系统时间被回调或改变，可能会造成ID冲突或者重复

![image-20240529101526086](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240529101526086.png)

不使用：1bit，最高位是符号位，0 表示正，1 表示负，固定为 0。

时间戳：41bit，毫秒级的时间戳（41 位的长度可以使用 69 年）。

标识位：5bit 数据中心 ID，5bit 工作机器 ID，两个标识位组合起来最多可以支持部署 1024 个节点（$2^{10}$）。

序列号：12bit 递增序列号，细分毫秒内，12bit 每毫秒可产生 4096 个 ID。

> 默认64bit，long，可以进行设置，扩充支持时间，扩充支持的节点数，增加序列号提升并发能力

### 重复问题

冲突前提：

1. 集群部署，部分机器标志位一致
2. 存在并发场景
3. 同一毫秒下才可能重复

### 标识位定义

Mybatis-Plus 标识位的获取依赖 Mac 地址和进程 PID，会有小几率问题

### 重复问题解决方案

##### 预分配

上线之前统计节点数，人工申请，不支持节点动态扩容

#### 动态分配

将标识位放在Redis、Zookeeper、MySQL 等中间件，在服务启动的时候去请求标识位

> 注意是全局唯一，还是服务内唯一

一种方案：

redis中使用`Hash`结构，包含两个键值对：`dataCenterId `和 `workerId`。

![image-20240529102347955](https://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240529102347955.png)

> 是一个循环结构，两个都到$2^{5}$之后，会归零重新开始

#### 开源分布式ID框架

Leaf 和 Uid 都有实现雪花算法，Leaf 额外提供了号段模式生成 ID。

美团 Leaf：https://github.com/Meituan-Dianping/Leaf

百度 Uid：https://github.com/baidu/uid-generator

> 大部分情况雪花算法就够了，不建议引入开源方案增加系统复杂度

## 敏感信息加密

`application.yaml` 配置文件修改配置，将数据库驱动变更为ShardingSphere Driver。

并配置 `shardingsphere-config.yaml` 相关配置。下边删除了分库分表的相关配置，仅保留了加密相关的配置

```yaml
# 配置数据源，底层被 ShardingSphere 进行了代理
dataSources:
  ds_0:
    dataSourceClassName: com.zaxxer.hikari.HikariDataSource
    driverClassName: com.mysql.cj.jdbc.Driver
    jdbcUrl: jdbc:mysql://127.0.0.1:3306/12306_user_0?useUnicode=true&characterEncoding=UTF-8&rewriteBatchedStatements=true&allowMultiQueries=true&serverTimezone=Asia/Shanghai
    username: root
    password: root

rules:
# 数据加密存储规则
  - !ENCRYPT
    # 需要加密的表集合
    tables:
      # 用户表
      t_user:
        # 用户表中哪些字段需要进行加密
        columns:
          # 身份证字段，逻辑字段，不一定是在数据库中真实存在
          id_card:
            # 身份证字段存储的密文字段，这个是数据库中真实存在的字段
            cipherColumn: id_card
            # 身份证字段加密算法
            encryptorName: common_encryptor
          phone:
            cipherColumn: phone
            encryptorName: common_encryptor
          mail:
            cipherColumn: mail
            encryptorName: common_encryptor
          address:
            cipherColumn: address
            encryptorName: common_encryptor
        # 是否按照密文字段查询
        queryWithCipherColumn: true
    # 加密算法
    encryptors:
      # 自定义加密算法名称
      common_encryptor:
        # 加密算法类型
        type: AES
        props:
          # AES 加密密钥
          aes-key-value: d6oadClrrb9A3GWo
props:
  sql-show: true
```

![image-20240611143011122](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240611143011122.png)

Apache ShardingSphere 会将用户请求的明文进行加密后存储到底层数据库；并在用户查询时，将密文从数据库中取出进行解密后返回给终端用户。 通过屏蔽对数据的加密处理，使用户无需感知解析 SQL、数据加密、数据解密的处理过程，就像在使用普通数据一样使用加密数据

## 令牌限流

### 常见限流算法

1. 固定窗口算法
2. 滑动窗口算法
3. 令牌桶算法
4. 漏桶算法

> [参考连接，见服务保护部分](https://b11et3un53m.feishu.cn/wiki/UkQtwZV8hiJHRnkH9iscjZbTnpg/)

### 令牌限流的优点

采用余票缓存也可以做限流，那么为什么要用令牌限流

#### 使用Redis缓存进行限流

具体实现：将列车余票放到缓存中，充当限流作用，通过 LUA 脚本扣减余票后，扣减成功代表余票数量充足，才可以进入流程分配座位，并创建订单，扣减失败请求打回。

![image-20240619164114152](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240619164114152.png)

#### 使用令牌容器

相对于上一种方案，拆分了一个令牌容器，其中存放的令牌就是列车余票数据。如果用户购买车票，需要先扣减令牌容器，扣减成功代表余票数量充足，扣减失败请求打回

> 用户查询列表所看到的余票数量，通过余票缓存，而不是令牌容器。

![image-20240619164159390](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240619164159390.png)

扣减令牌容器后，对余票缓存并没有影响，只有在修改了座位表后，才会通过 Canal 形式监听并减少余票缓存

#### 使用令牌容器的优点

极端情况：扣减余票缓存容器成功后，然后应用宕机，导致余票缓存和余票数据库库存不一致

如果有令牌容器，发现没有剩余可用令牌，那么我们可以进行兜底判断，也可以叫做二次检查。触发一个请求去比对数据库是否还有值，如果有的话，那么就把令牌容器缓存删除，下个用户再购票时，重新加载即可

:question:代码部分待看

也可以仅使用余票缓存做数据展示

## 缓存击穿之双重判定锁如何优化性能？

方案：分布式锁

原始分布式锁的问题：

- 100w数据请求一个缓存，除了一个获取到的，其他的都会阻塞
- 但阻塞之后还是会继续请求

优化方案：双重判定，查询数据库之前，再次检查缓存中是否存在数据

## 缓存与数据库一致性解决

### 技术方案

#### 1. 先写缓存再数据库

![image-20240619165949639](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240619165949639.png)

#### 2. 先写数据库再写缓存

![image-20240619170005020](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240619170005020.png)

上述两种都存在较大的并发问题

#### 3. 先删除缓存再写数据库

![image-20240619170205464](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240619170205464.png)

假设有两个并发的读写操作，一个是写操作，另一个是读操作。

1. 并发读写的情况下，写操作首先删除缓存，接下来需要执行更新数据库操作。
2. 读操作发生，由于缓存已经被删除，读操作不得不从数据库中读取数据。然而，由于写操作尚未完成，数据库中的数据仍然是过时的。
3. 写操作这时需要更新数据库中的值，更新后 MySQL 数据库是最新的值。
4. 读操作将从数据库中查询到的过时数据再回写到缓存。

在这种情况下，读操作获取到的是过时的数据，尽管写操作已经完成。因为缓存被删除，读操作不得不从数据库中读取旧值，而不是最新的值

#### 4. 缓存双删

![image-20240620085944107](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240620085944107.png)

需要保证的就是，第二次删除要在读请求写会缓存之后

解决方案：使用延迟队列或第三方消息队列，做一个类似睡眠的操作

![image-20240620090059627](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240620090059627.png)

可以达到最终一致性

#### 5. 先写数据库再删除缓存

![image-20240620090425827](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240620090425827.png)

一般情况下存在很小的周期的数据不一致

下图是缓存失效时的情况，但出现情况极低

![image-20240620090819908](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240620090819908.png)

对于绝大多数的情况来说，可以容忍数据的短期不一致。除去一些电商库存、列车余票等对数据比较敏感的情况，比较适合绝大多数业务场景。

#### 6.  先写数据库，通过 BinLog 异步更新缓存

![image-20240620091417770](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240620091417770.png)

#### 	总结

可以根据业务场景选择下述缓存一致性方案：

- [缓存双删](https://www.yuque.com/magestack/12306/glv5e0785b2d7oag#NZlgQ)：如果公司现有消息队列中间件，可以考虑使用该方案，反之则不需要考虑。
- [先写数据库再删缓存](https://www.yuque.com/magestack/12306/glv5e0785b2d7oag#w4hgF)：这种方案从实时性以及技术实现复杂度来说都比较不错，推荐大家使用这种方案。
- [Binlog 异步更新缓存](https://www.yuque.com/magestack/12306/glv5e0785b2d7oag#shlMA)：如果希望实现最终一致性以及数据多中心模式，该方案无疑是最合适的。

## 策略模式

什么是策略模式：定义一组算法类，**将每个算法分别封装起来，让它们可以互相替换**。策略模式使这些算法在客户端调用它们的时候能够互不影响地变化，客户端代指使用算法的代码。

策略设计模式步骤

1. 定义抽象策略接口，因为业务使用接口而不是具体的实现类的话，便可以灵活的替换不同的策略；
2. 定义具体策略实现类，实现自抽象策略接口，其内部封装具体的业务实现；
3. 定义策略工厂，封装创建策略实现（算法），对客户端屏蔽具体的创建细节。

![image-20240620144002550](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240620144002550.png)

客户端具体使用

![image-20240620144032689](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240620144032689.png)

上述缺点：

- 虽然新增优惠策略，只需要新增一个策略算法实现类即可
- 但，需要修改策略工厂中的代码

### 实际应用场景

借助Spring帮助，彻底实现开闭

![image-20240620144249070](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240620144249070.png)

1. 抽象策略接口中，新定义了 mark() 接口，此接口用来标示算法的唯一性；
2. 具体策略实现类，使用 @Component  修饰，将对象本身交由 Spring 进行管理 

![image-20240620144424853](http://pig-test-qz.oss-cn-beijing.aliyuncs.com/img/image-20240620144424853.png)

和之前责任链模式相同 ，都是通过 InitializingBean 接口实现中调用 IOC 容器查找对应策略实现，随后将策略实现 mark() 方法返回值作为 key， 策略实现本身作为 value 添加到 Map 容器中等待客户端的调用。

> `InitializingBean`接口用于提供一种机制，允许bean在其所有的属性被Spring容器设置后，可以执行初始化的代码。当一个bean实现了`InitializingBean`接口，Spring容器会在设置完bean的所有属性后调用`afterPropertiesSet()`方法

客户端使用与之前不使用Spirng的时候类似

### 策略模式的优缺点

优点：

1. 提高了代码的灵活性和可维护性：由于算法的实现与使用相分离，使得代码的灵活性和可维护性得到提高。当需要修改或添加新的算法时，只需要定义新的策略类，并将其传递给环境类即可，而无需修改环境类的代码。
2. 提高了代码的复用性：策略设计模式将算法的实现封装在策略类中，使得算法可以被多个客户端重复使用，从而提高了代码的复用性。
3. 可以动态地切换算法：策略设计模式将算法封装在策略类中，使得可以在运行时动态地更改算法，从而实现不同的功能和行为。这样可以使得程序更加灵活，适应不同的需求和变化。
4. 算法实现与使用相分离：策略设计模式将算法的实现与使用相分离，使得代码更加清晰、简洁、易于维护和扩展。由于算法的实现被封装在策略类中，客户端只需要关注如何选择和使用不同的算法即可，这样可以使得代码更加易于理解和维护。
5. 可以避免使用大量的条件语句：在某些情况下，需要根据不同的条件来选择不同的算法，这可能会导致代码中出现大量的条件语句，使得代码难以维护和扩展。而策略设计模式可以避免这种情况的发生，使得代码更加简洁和易于维护。

### 策略模式抽象

重复定义 `DiscountStrategy` 以及 `DiscountStrategyFactory` 会增加系统冗余代码量，故进行进一步的抽象

```java
package org.opengoofy.congomall.springboot.starter.designpattern.strategy;

/**
 * 策略执行抽象
 */
public interface AbstractExecuteStrategy<REQUEST, RESPONSE> {

    /**
     * 执行策略标识
     */
    String mark();

    /**
     * 执行策略
     *
     * @param requestParam 执行策略入参
     */
    default void execute(REQUEST requestParam) {

    }

    /**
     * 执行策略，带返回值
     *
     * @param requestParam 执行策略入参
     * @return 执行策略后返回值
     */
    default RESPONSE executeResp(REQUEST requestParam) {
        return null;
    }
}
```

添加策略选择器，通过订阅 Spring 初始化事件执行扫描所有策略模式接口执行器，并根据 mark 方法定义标识添加到 `abstractExecuteStrategyMap` 容器中。

客户端在实际业务中使用 `AbstractStrategyChoose#choose` 即可完成策略模式实现

```java
package org.opengoofy.congomall.springboot.starter.designpattern.strategy;

import org.opengoofy.congomall.springboot.starter.base.ApplicationContextHolder;
import org.opengoofy.congomall.springboot.starter.base.init.ApplicationInitializingEvent;
import org.opengoofy.congomall.springboot.starter.convention.exception.ServiceException;
import org.springframework.context.ApplicationListener;

import java.util.HashMap;
import java.util.Map;
import java.util.Optional;

/**
 * 策略选择器
 */
public class AbstractStrategyChoose implements ApplicationListener<ApplicationInitializingEvent> {

    /**
     * 执行策略集合
     */
    private final Map<String, AbstractExecuteStrategy> abstractExecuteStrategyMap = new HashMap<>();

    /**
     * 根据 mark 查询具体策略
     *
     * @param mark 策略标识
     * @return 实际执行策略
     */
    public AbstractExecuteStrategy choose(String mark) {
        return Optional.ofNullable(abstractExecuteStrategyMap.get(mark)).orElseThrow(() -> new ServiceException(String.format("[%s] 策略未定义", mark)));
    }

    /**
     * 根据 mark 查询具体策略并执行
     *
     * @param mark         策略标识
     * @param requestParam 执行策略入参
     * @param <REQUEST>    执行策略入参范型
     */
    public <REQUEST> void chooseAndExecute(String mark, REQUEST requestParam) {
        AbstractExecuteStrategy executeStrategy = choose(mark);
        executeStrategy.execute(requestParam);
    }

    /**
     * 根据 mark 查询具体策略并执行，带返回结果
     *
     * @param mark         策略标识
     * @param requestParam 执行策略入参
     * @param <REQUEST>    执行策略入参范型
     * @param <RESPONSE>   执行策略出参范型
     * @return
     */
    public <REQUEST, RESPONSE> RESPONSE chooseAndExecuteResp(String mark, REQUEST requestParam) {
        AbstractExecuteStrategy executeStrategy = choose(mark);
        return (RESPONSE) executeStrategy.executeResp(requestParam);
    }

    @Override
    public void onApplicationEvent(ApplicationInitializingEvent event) {
        Map<String, AbstractExecuteStrategy> actual = ApplicationContextHolder.getBeansOfType(AbstractExecuteStrategy.class);
        actual.forEach((beanName, bean) -> {
            AbstractExecuteStrategy beanExist = abstractExecuteStrategyMap.get(bean.mark());
            if (beanExist != null) {
                throw new ServiceException(String.format("[%s] Duplicate execution policy", bean.mark()));
            }
            abstractExecuteStrategyMap.put(bean.mark(), bean);
        });
    }
}
```